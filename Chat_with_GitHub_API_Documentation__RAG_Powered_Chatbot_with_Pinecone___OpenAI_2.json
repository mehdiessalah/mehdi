{
  "name": "Chat with GitHub API Documentation: RAG-Powered Chatbot with Pinecone & OpenAI 2",
  "nodes": [
    {
      "parameters": {},
      "id": "362cb773-7540-4753-a401-e585cdf4af8a",
      "name": "When clicking ‘Test workflow’",
      "type": "n8n-nodes-base.manualTrigger",
      "position": [
        1200,
        500
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "url": "https://github.com/mehdiessalah/mehdi/blob/15bf57ec0cf58cf27ab82dd3f94ff03bff2ae670/optimized_car_data.json",
        "options": {}
      },
      "id": "45470036-cae6-48d0-ac66-addc8999e776",
      "name": "HTTP Request",
      "type": "n8n-nodes-base.httpRequest",
      "position": [
        1500,
        500
      ],
      "typeVersion": 4.2
    },
    {
      "parameters": {
        "mode": "insert",
        "pineconeIndex": {
          "__rl": true,
          "value": "n8n",
          "mode": "list",
          "cachedResultName": "n8n"
        },
        "options": {}
      },
      "id": "a9e65897-52c9-4941-bf49-e1a659e442ef",
      "name": "Pinecone Vector Store",
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "position": [
        1720,
        500
      ],
      "typeVersion": 1,
      "credentials": {
        "pineconeApi": {
          "id": "UlPJ6g9XAtEu1Xip",
          "name": "PineconeApi account"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "id": "c2a2354b-5457-4ceb-abfc-9a58e8593b81",
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "position": [
        1860,
        680
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "options": {}
      },
      "id": "7338d9ea-ae8f-46eb-807f-a15dc7639fc9",
      "name": "Recursive Character Text Splitter",
      "type": "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter",
      "position": [
        1940,
        860
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "options": {}
      },
      "id": "44fd7a59-f208-4d5d-a22d-e9f8ca9badf1",
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "position": [
        1180,
        1260
      ],
      "webhookId": "089e38ab-4eee-4c34-aa5d-54cf4a8f53b7",
      "typeVersion": 1.1
    },
    {
      "parameters": {
        "options": {
          "systemMessage": "You are an AI assistant specialized in answering questions about car details. Your primary task is to provide accurate and relevant information based on the data provided, which includes various car models, features, prices, and specifications.\n\nThe data you will use is located in a file named `scrapped_data.json`, which contains question and answer pairs related to car details, scraped from a car dealership website. This data includes links to cars available for different budgets.\n\nWhenever you receive a question, refer to this data and provide a concise and informative answer. If a user asks about cars within a specific budget or with specific features, search the JSON data to find and list the relevant cars.\n\nYour responses should be clear, concise, and helpful. If you do not have enough information to answer a question, indicate that the information is not available.\n\nRemember, you are here to assist users in finding detailed information about cars, including but not limited to model specifications, pricing, features, and other related details, including links to cars within specific budget ranges."
        }
      },
      "id": "51d819d6-70ff-428d-aa56-1d7e06490dee",
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [
        1520,
        1260
      ],
      "typeVersion": 1.7
    },
    {
      "parameters": {
        "options": {}
      },
      "id": "aed548bf-7083-44ad-a3e0-163dee7423ef",
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "position": [
        1420,
        1480
      ],
      "typeVersion": 1.1,
      "credentials": {
        "openAiApi": {
          "id": "as5HSEVwOY9DeHAG",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {},
      "id": "dfe9f356-2225-4f4b-86c7-e56a230b4193",
      "name": "Window Buffer Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "position": [
        1620,
        1520
      ],
      "typeVersion": 1.3
    },
    {
      "parameters": {
        "name": "cars_details",
        "description": "Useful for when you need to answer questions about cars details. Whenever you need information about various car models, features, prices, and specifications, including links to cars available for different budgets, you should ALWAYS use this. Input should be a fully formed question."
      },
      "id": "4cf672ee-13b8-4355-b8e0-c2e7381671bc",
      "name": "Vector Store Tool",
      "type": "@n8n/n8n-nodes-langchain.toolVectorStore",
      "position": [
        1780,
        1480
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "options": {}
      },
      "id": "1df7fb85-9d4a-4db5-9bed-41d28e2e4643",
      "name": "OpenAI Chat Model1",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "position": [
        2040,
        1660
      ],
      "typeVersion": 1.1,
      "credentials": {
        "openAiApi": {
          "id": "as5HSEVwOY9DeHAG",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "content": "## Indexing content in the vector database\nThis part of the workflow is responsible for extracting content, generating embeddings and sending them to the Pinecone vector store.\n\nIt requests the OpenAPI specifications from GitHub using a HTTP request. Then, it splits the file in chunks, generating embeddings for each chunk using OpenAI, and saving them in Pinecone vector DB.",
        "height": 200,
        "width": 640
      },
      "id": "7b52ef7a-5935-451e-8747-efe16ce288af",
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1160,
        240
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "content": "## Querying and response generation \n\nThis part of the workflow is responsible for the chat interface, querying the vector store and generating relevant responses.\n\nIt uses OpenAI GPT 4o-mini to generate responses.",
        "width": 580
      },
      "id": "3508d602-56d4-4818-84eb-ca75cdeec1d0",
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1180,
        1060
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "options": {}
      },
      "id": "5a9808ef-4edd-4ec9-ba01-2fe50b2dbf4b",
      "name": "Generate User Query Embedding",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "position": [
        1680,
        1900
      ],
      "typeVersion": 1.2,
      "credentials": {
        "openAiApi": {
          "id": "as5HSEVwOY9DeHAG",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "pineconeIndex": {
          "__rl": true,
          "value": "n8n",
          "mode": "list",
          "cachedResultName": "n8n"
        },
        "options": {}
      },
      "id": "f703dc8e-9d4b-45e3-8994-789b3dfe8631",
      "name": "Pinecone Vector Store (Querying)",
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "position": [
        1640,
        1720
      ],
      "typeVersion": 1,
      "credentials": {
        "pineconeApi": {
          "id": "UlPJ6g9XAtEu1Xip",
          "name": "PineconeApi account"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "id": "ea64a7a5-1fa5-4938-83a9-271929733a8e",
      "name": "Generate Embeddings",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "position": [
        1680,
        720
      ],
      "typeVersion": 1.2,
      "credentials": {
        "openAiApi": {
          "id": "as5HSEVwOY9DeHAG",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "content": "## RAG workflow in n8n\n\nThis is an example of how to use RAG techniques to create a chatbot with n8n. It is an API documentation chatbot that can answer questions about the GitHub API. It uses OpenAI for generating embeddings, the gpt-4o-mini LLM for generating responses and Pinecone as a vector database.\n\n### Before using this template\n* create OpenAI and Pinecone accounts\n* obtain API keys OpenAI and Pinecone \n* configure credentials in n8n for both\n* ensure you have a Pinecone index named \"n8n-demo\" or adjust the workflow accordingly.",
        "height": 320,
        "width": 620
      },
      "id": "65cbd4e3-91f6-441a-9ef1-528c3019e238",
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        380,
        240
      ],
      "typeVersion": 1
    }
  ],
  "pinData": {},
  "connections": {
    "HTTP Request": {
      "main": [
        [
          {
            "node": "Pinecone Vector Store",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Vector Store Tool": {
      "ai_tool": [
        [
          {
            "node": "AI Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "Vector Store Tool",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Default Data Loader": {
      "ai_document": [
        [
          {
            "node": "Pinecone Vector Store",
            "type": "ai_document",
            "index": 0
          }
        ]
      ]
    },
    "Generate Embeddings": {
      "ai_embedding": [
        [
          {
            "node": "Pinecone Vector Store",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "Window Buffer Memory": {
      "ai_memory": [
        [
          {
            "node": "AI Agent",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "When chat message received": {
      "main": [
        [
          {
            "node": "AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate User Query Embedding": {
      "ai_embedding": [
        [
          {
            "node": "Pinecone Vector Store (Querying)",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "Pinecone Vector Store (Querying)": {
      "ai_vectorStore": [
        [
          {
            "node": "Vector Store Tool",
            "type": "ai_vectorStore",
            "index": 0
          }
        ]
      ]
    },
    "Recursive Character Text Splitter": {
      "ai_textSplitter": [
        [
          {
            "node": "Default Data Loader",
            "type": "ai_textSplitter",
            "index": 0
          }
        ]
      ]
    },
    "When clicking ‘Test workflow’": {
      "main": [
        [
          {
            "node": "HTTP Request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "57f7baa2-39a2-4057-bbf3-c6866a8802c9",
  "meta": {
    "templateId": "2705",
    "templateCredsSetupCompleted": true,
    "instanceId": "2fc9765845ee45f6cd30a90dfcd4af57f558255de2e6b070406ad5acf18c5981"
  },
  "id": "ZJ0Qh8N0JkrWBQFw",
  "tags": []
}